{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Expanded Context\n",
    "\n",
    "### Expand - Connect Form 10k Chunk Nodes\n",
    "\n",
    "The Form 10k Chunk Nodes are individual chunks of text that used\n",
    "to be part of an entire document.\n",
    "\n",
    "You can reconstruct the original context by connecting the nodes\n",
    "with relationships. \n",
    "\n",
    "This is the second step in creating a knowledge graph. \n",
    "\n",
    "First, create nodes. Then, connect the nodes with relationships.\n",
    "\n",
    "The creates a connected context which can improve answers in a RAG application.\n",
    "\n",
    "It also makes the data easy to navigate and understand.\n",
    "\n",
    "That is super helpful when you're building an application, for debugging and testing.\n",
    "\n",
    "And, you can provide a better user experience. Your users will be able \n",
    "to directly interact with the data and even provide feedback that will\n",
    "improve subsequent answers. \n",
    "\n",
    "You will create a connected context by making the following\n",
    "changes to the knowledge graph:\n",
    "\n",
    "1. First, connect each chunk into a linked list.\n",
    "2. Second, create `(:Form)` nodes for each original source Form.\n",
    "3. Third, connect each chunk to the parent `(:Form)` node that it is a part of.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - import libraries\n",
    "\n",
    "You need to import some libaries, as usual, so let's do that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Global constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - set up global constants\n",
    "\n",
    "You will also define some global constants for the database connection,\n",
    "and the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j://localhost:7687 neo4j\n"
     ]
    }
   ],
   "source": [
    "print(NEO4J_URI, NEO4J_USERNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a knowledge graph using Langchain's Neo4j integration.\n",
    "# This will be used for direct querying of the knowledge graph. \n",
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Form` Nodes\n",
    "\n",
    "You already have Chunk nodes.\n",
    "\n",
    "You want to create a new node to represent the 10k form itself.\n",
    "\n",
    "Each node will have a `Form` label, and the following properties:\n",
    "  - formId - a unique identifier for the form\n",
    "  - source - a link back to the original 10k document\n",
    "  - cik - the Central Index Key for the company that filed the form\n",
    "  - cusip6 - the CUSIP identifier for the company\n",
    "\n",
    "As a node, it will look like this:\n",
    "```cypher\n",
    "(:Form \n",
    "  formId: string\n",
    "  source: string\n",
    "  cik: int\n",
    "  cusip6: string\n",
    ")\n",
    "```\n",
    "\n",
    "(Possible slide?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cypher Queries to tranform the Knowledge Graph\n",
    "\n",
    "### First, create Form nodes\n",
    "\n",
    "You can now use these Cypher features to transform the graph.\n",
    "\n",
    "You will start by creating `Form` nodes. \n",
    "There will be one Form node for every Form 10k.\n",
    "\n",
    "The first step is to look through all the Chunks and \n",
    "find the `formId` that they came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cik': '1650372',\n",
       " 'source': 'https://www.sec.gov/Archives/edgar/data/1650372/000165037223000040/0001650372-23-000040-index.htm',\n",
       " 'formId': '0001650372-23-000040',\n",
       " 'names': ['ATLASSIAN CORP PLC', 'ATLASSIAN CORPORATION PLC'],\n",
       " 'cusip6': 'G06242'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find distinct information needed for each Form Node...\n",
    "\n",
    "# MATCH the same single node pattern \n",
    "# RETURN DISTINCT rows of `source`, `formId`, `cik`, and `cusip6` properties\n",
    "\n",
    "\n",
    "cypher = \"\"\"\n",
    "  MATCH (anyChunk:Chunk) \n",
    "  WITH anyChunk LIMIT 1\n",
    "  RETURN anyChunk { .names, .source, .formId, .cik, .cusip6 } as formInfo\n",
    "\"\"\"\n",
    "form_info_list = kg.query(cypher)\n",
    "\n",
    "form_info_list\n",
    "\n",
    "all_form_info = [form_info['formInfo'] for form_info in form_info_list]\n",
    "\n",
    "all_form_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a constraint for Forms\n",
    "\n",
    "Before creating Form nodes,\n",
    "create a uniqueness constraint on nodes with a `Form` label\n",
    "requiring that the `formId` property is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a uniqueness constraint on the textId property of Text nodes \n",
    "kg.query('CREATE CONSTRAINT unique_form IF NOT EXISTS FOR (n:Form) REQUIRE n.formId IS UNIQUE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create *all* parent form nodes (skip for single form)\n",
    "\n",
    "You can now create a Form node for each of the distinct formIds\n",
    "using distinct rows.\n",
    "\n",
    "For each row, \n",
    "`MERGE` a new `(:Form)` node\n",
    "with source, cik, and cusip6 properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'formCount': 10}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parent `Form` nodes for each form..\n",
    "\n",
    "# MATCH the same single node pattern \n",
    "# WITH DISTINCT rows of `source`, `formId`, `cik`, and `cusip6` properties\n",
    "# MERGE a new `Form` node with the `formId` property\n",
    "# and SET the `source`, `cik`, and `cusip6` properties\n",
    "cypher = \"\"\"\n",
    "  MATCH (all:Chunk) \n",
    "  WITH DISTINCT all {.names, .source, .formId, .cik,.cusip6} as formInfo\n",
    "    MERGE (f:Form {formId: formInfo.formId })\n",
    "      ON CREATE \n",
    "        SET f.names = formInfo.names\n",
    "        SET f.source = formInfo.source\n",
    "        SET f.cik = formInfo.ci\n",
    "        SET f.cusip6 = formInfo.cusip6\n",
    "    RETURN count(f) as formCount\n",
    "\"\"\"\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - connect chunks into linked list\n",
    "\n",
    "You can now create relationships between all\n",
    "nodes in that list of chunks,\n",
    "effectively creating a linked list from the\n",
    "first chunk to the last.\n",
    "\n",
    "The extra step here is calling the `apoc.nodes.link` \n",
    "procedure to create a linked list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - connect *all* chunks (multiple forms)\n",
    "\n",
    "You can now connect all the chunks into linked lists\n",
    "by looping through all the distinct formIds and sections,\n",
    "calling the same cypher query as above \n",
    "to connect the related section chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect *all* section chunks into a linked list..\n",
    "\n",
    "# MATCH the same single node pattern \n",
    "# WITH all DISTINCT sources, CALL a subquery\n",
    "# within the subquery, MATCH a new single node pattern\n",
    "# WHERE the chunks have the same `source` property \n",
    "# and are part of the same section named by the `f10kItem` property\n",
    "# WITH those chunks collected together\n",
    "# CALL apoc.nodes.link() to create a linked list\n",
    "cypher = \"\"\"\n",
    "  MATCH (from_same_form_and_section:Chunk)\n",
    "  WHERE from_same_form_and_section.formId = $formIdParam\n",
    "    AND from_same_form_and_section.f10kItem = $f10kItemParam\n",
    "  WITH from_same_form_and_section\n",
    "    ORDER BY from_same_form_and_section.chunkSeqId ASC\n",
    "  WITH collect(from_same_form_and_section) as section_chunk_list\n",
    "    CALL apoc.nodes.link(section_chunk_list, \"NEXT\", {avoidDuplicates: true})\n",
    "  RETURN size(section_chunk_list)\n",
    "\"\"\"\n",
    "\n",
    "distinct_form_ids = list(map(lambda form_info: form_info['formId'], all_form_info))\n",
    "for form_id in distinct_form_ids:\n",
    "  for form10kItemName in ['item1', 'item1a', 'item7', 'item7a']:\n",
    "    kg.query(cypher, params={'formIdParam':form_id, 'f10kItemParam': form10kItemName})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - connect chunks to parent Form nodes\n",
    "\n",
    "Next, you can connect the chunks to the Form they're part of.\n",
    "\n",
    "Match a Chunk and a Form\n",
    "where they have the same `formId`,\n",
    "then `MERGE` a new `PART_OF` relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(newRelationship)': 544}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect all chunks to their parent `Form` node...\n",
    "\n",
    "# MATCH a double node pattern, for the `Chunk` and `Form` nodes\n",
    "# WHERE the `Chunk` and `Form` nodes have the same `formId` property\n",
    "# connect the pairs into a (:Chunk)-[:PART_OF]->(:Form) relationship\n",
    "cypher = \"\"\"\n",
    "  MATCH (c:Chunk), (f:Form)\n",
    "    WHERE c.formId = f.formId\n",
    "  MERGE (c)-[newRelationship:PART_OF]->(f)\n",
    "  RETURN count(newRelationship)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - connect `Form` to head of `Chunk` list\n",
    "\n",
    "You can add one more relationship to the graph, connecting\n",
    "the `Form` to the first `Chunk` of each section.\n",
    "\n",
    "This is similar to the previous query,\n",
    "but also checks that the chunk sequence id is 0.\n",
    "\n",
    "The `SECTION` relationship that connects the Form to the\n",
    "first chunk will also get an `f10kItem` property.\n",
    "\n",
    "This is a kindness for humans looking at the knowledge graph,\n",
    "enabling them to eaily navigate from a Form to the beginning\n",
    "of a particular section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(newRelationship)': 40}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect all parent `Form` nodes to the \"head\" of each section linked list...\n",
    "\n",
    "# MATCH a double node pattern, for the `Chunk` and `Form` nodes\n",
    "# WHERE the `Chunk` and `Form` nodes have the same `formId` property\n",
    "# (this is exactly like a JOIN in SQL)\n",
    "# connect the pairs with a (:Chunk)-[:PART_OF]->(:Form) relationship\n",
    "cypher = \"\"\"\n",
    "  MATCH (headOfSection:Chunk), (f:Form)\n",
    "  WHERE headOfSection.formId = f.formId\n",
    "    AND headOfSection.chunkSeqId = 0\n",
    "  WITH headOfSection, f\n",
    "    MERGE (f)-[newRelationship:SECTION {f10kItem:headOfSection.f10kItem}]->(headOfSection)\n",
    "  RETURN count(newRelationship)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example cypher queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - pattern match from form to head of section \n",
    "\n",
    "For example, you can get the first chunk for a section\n",
    "using a pattern match from a form to the chunk\n",
    "connected by a `SECTION` relationship with a matching `f10kItem` property.\n",
    "\n",
    "As you'd expect the text of this \"first chunk\" looks familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001650372-23-000040'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_form_info[0]['formId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunkId': '0001650372-23-000040-item1-chunk0000',\n",
       "  'text': '>ITEM\\xa01. BUSINESS\\nCompany Overview\\n\\xa0\\nOur mission is to unleash the potential of every team.\\nOur products help teams organize, discuss and complete shared work â€” delivering superior outcomes for their organizations.\\nOur primary products include Jira Software and Jira Work Management for planning and project management, Confluence for content creation and sharing, Trello for capturing and adding structure to fluid, fast-forming work for teams, Jira Service Management for team service, management and support applications, Jira Align for enterprise agile planning, and Bitbucket for code sharing and management. Together, our products form an integrated system for organizing, discussing and completing shared work, becoming deeply entrenched in how teams collaborate and how organizations run. The Atlassian platform is the common technology foundation for our products that drives connection between teams, information, and workflows. It allows work to flow seamlessly across tools, automates the mundane so teams can focus on what matters, and enables better decision-making based on the data customers choose to put into our products.\\nOur products serve teams of all shapes and sizes, in virtually every industry. Our pricing strategy is unique within the enterprise software industry because we transparently share our affordable pricing online for most of our products and we generally do not follow the practice of opaque pricing and ad hoc discounting. By delivering high-value, low cost products in pursuit of customer volume, and targeting every organization, regardless of size, industry, or geography we are able to operate at unusual scale for an enterprise software company, with more than 260,000 customers across virtually every industry sector in approximately 200 countries as of June\\xa030, 2023.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (f:Form)-[r:SECTION]->(first:Chunk)\n",
    "    WHERE f.formId = $formIdParam\n",
    "        AND r.f10kItem = $f10kItemParam\n",
    "  RETURN first.chunkId as chunkId, first.text as text\n",
    "\"\"\"\n",
    "\n",
    "first_chunk_info = kg.query(cypher, params={\n",
    "    'formIdParam': all_form_info[0]['formId'], \n",
    "    'f10kItemParam': 'item1'\n",
    "})\n",
    "\n",
    "first_chunk_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare langchain for using the Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - chain with cypher\n",
    "\n",
    "You can now create a question and answer chain.\n",
    "\n",
    "The default Neo4jVector uses a basic cypher query\n",
    "to peform vector similarity search.\n",
    "\n",
    "That query can be extended to do whatever you\n",
    "want in a Cypher.\n",
    "\n",
    "...\n",
    "\n",
    "This Cypher query extension will receive two variables: `node` and `score`.\n",
    "\n",
    "The query should return three columns: `text`, `score`, and `metadata`.\n",
    "\n",
    "The `text` should be plain text to be passed to the LLM.\n",
    "\n",
    "The `score` column should be the similarity score of the text.\n",
    "\n",
    "The `metadata` can be any additional information you want to pass, \n",
    "\n",
    "like the source of the text.\n",
    "\n",
    "...\n",
    "\n",
    "The Cypher itself can do whatever you want to create those outputs.\n",
    "\n",
    "This example has a literal string that is prepended to any text.\n",
    "\n",
    "\n",
    "Create an extended Neo4j vector store by providing\n",
    "a parameter called `retrieval_query`\n",
    "where we pass in the Cypher query extension.\n",
    "\n",
    "...\n",
    "\n",
    "The retriever and chain construction is exactly the same as before.\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "This \"extra text\" will be prepended to any chunks that are\n",
    "found by the vector search. This expands the context of the\n",
    "information passed to the LLM. This is new information that\n",
    "may not have been present in the chunk text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - langchain with and without the window\n",
    "\n",
    "You now know how to customize the results of a vector\n",
    "search by extending it with Cypher.\n",
    "\n",
    "You could use this capability to expand the context\n",
    "around a chunk with the chunk window query.\n",
    "\n",
    "Let's try this out and compare results.\n",
    "\n",
    "...\n",
    "\n",
    "First, create a chain that uses the default cypher\n",
    "query included with Neo4jVector. That query performs\n",
    "a vector search using the specified configuration.\n",
    "\n",
    "Call it \"windowless_chain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(chain):\n",
    "    def prettychain(question:str):\n",
    "      response = chain({\"question\": question},return_only_outputs=True,)\n",
    "      print(textwrap.fill(response['answer'], 80))\n",
    "    return prettychain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a langchain vector store from the existing Neo4j knowledge graph.\n",
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n",
    "# Create a retriever from the vector store\n",
    "windowless_retriever = neo4j_vector_store.as_retriever()\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "windowless_chain = prettify(RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=windowless_retriever\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script - chain with cypher\n",
    "\n",
    "Now create another chain that uses the\n",
    "chunk window query.\n",
    "\n",
    "Your goal here is to expand the context with adjacent\n",
    "chunks which may be relevant to providing a complete\n",
    "answer.\n",
    "\n",
    "To do that, use the chunk window query, then pull\n",
    "out text from each chunk that is in the window.\n",
    "\n",
    "Finally, all that text will be concatenated together\n",
    "to provide a complete context for the LLM.\n",
    "\n",
    "...\n",
    "\n",
    "That the top `MATCH` clause uses the\n",
    "special `node` variable in the middle of the pattern\n",
    "\n",
    "There is an extra `WITH` that collects the text from\n",
    "each chunk into a list.\n",
    "\n",
    "The `RETURN` clause uses the `apoc.text.join` function\n",
    "to concatenate that list of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query_window = \"\"\"\n",
    "MATCH window=\n",
    "    (:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
    "WITH node, score, window as longestWindow \n",
    "  ORDER BY length(window) DESC LIMIT 1\n",
    "WITH nodes(longestWindow) as chunkList, node, score\n",
    "  UNWIND chunkList as chunkRows\n",
    "WITH collect(chunkRows.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\n \") as text,\n",
    "    score,\n",
    "    node {.source} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "vector_store_window = Neo4jVector.from_existing_index(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=\"neo4j\",\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    text_node_property=VECTOR_SOURCE_PROPERTY,\n",
    "    retrieval_query=retrieval_query_window\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever_window = vector_store_window.as_retriever()\n",
    "\n",
    "# Create a chatbot Question & Answer chain from the retriever\n",
    "chain_window = prettify(RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_window\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example questions - compare with and without context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about Fedex's business.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedEx Corporation provides customers and businesses worldwide with a broad\n",
      "portfolio of transportation, e-commerce, and business services through its\n",
      "operating companies, including FedEx Express, FedEx Ground, and FedEx Freight.\n",
      "FedEx operates collaboratively and innovates digitally as one company. FedEx has\n",
      "a global network that connects more than 99% of the world's gross domestic\n",
      "product. FedEx has introduced innovative solutions and initiatives to improve\n",
      "long-term profitability and service quality.\n"
     ]
    }
   ],
   "source": [
    "windowless_chain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedEx Corporation provides customers and businesses worldwide with a broad\n",
      "portfolio of transportation, e-commerce, and business services through its\n",
      "operating companies, FedEx Express and FedEx Ground.\n"
     ]
    }
   ],
   "source": [
    "chain_window(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
